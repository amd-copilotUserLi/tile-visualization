#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONå’ŒExcelæ•°æ®æ•´åˆå·¥å…·
ç”¨äºæ•´åˆchip_blocks.jsonå’ŒMapping.xlsxçš„æ•°æ®
"""

import pandas as pd
import json
import os
import re
from pathlib import Path

def read_excel_mapping_data(excel_file_path):
    """
    è¯»å–Excelæ–‡ä»¶çš„Aã€Bã€Cã€Fåˆ—æ•°æ®ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
    
    Args:
        excel_file_path: Excelæ–‡ä»¶è·¯å¾„
        
    Returns:
        list: åŒ…å«mappingæ•°æ®çš„å­—å…¸åˆ—è¡¨
    """
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    if not os.path.isabs(excel_file_path):
        excel_file_path = os.path.join(os.path.dirname(__file__), '..', 'input', excel_file_path)
    
    excel_file_path = os.path.abspath(excel_file_path)
    
    if not os.path.exists(excel_file_path):
        raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file_path}")
    
    try:
        # è¯»å–Excelæ–‡ä»¶çš„Aã€Bã€Cã€Fåˆ—ï¼ˆç´¢å¼•ä¸º0ã€1ã€2ã€5ï¼‰
        df = pd.read_excel(excel_file_path, usecols=[0, 1, 2, 5], skiprows=1, header=None)
        
        # é‡å‘½ååˆ—
        df.columns = ['module', 'instance', 'dbg_blk_id', 'tile_name']
        
        # è¿‡æ»¤æ‰æ‰€æœ‰åˆ—éƒ½ä¸ºç©ºçš„è¡Œ
        mapping_data = []
        for _, row in df.iterrows():
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®ï¼ˆè‡³å°‘moduleã€instanceã€dbg_blk_idä¸ä¸ºç©ºï¼‰
            if (pd.notna(row['module']) and str(row['module']).strip() and
                pd.notna(row['instance']) and str(row['instance']).strip() and
                pd.notna(row['dbg_blk_id']) and str(row['dbg_blk_id']).strip()):
                
                mapping_entry = {
                    'module': str(row['module']).strip(),
                    'instance': str(row['instance']).strip(),
                    'dbg_blk_id': str(row['dbg_blk_id']).strip(),
                    'tile_name': str(row['tile_name']).strip() if pd.notna(row['tile_name']) and str(row['tile_name']).strip() else ""
                }
                mapping_data.append(mapping_entry)
        
        print(f"âœ… ä»Excelæ–‡ä»¶è¯»å–åˆ° {len(mapping_data)} æ¡æœ‰æ•ˆçš„mappingæ•°æ®")
        return mapping_data
        
    except Exception as e:
        print(f"âŒ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def clean_dbg_blk_id(dbg_blk_id_str):
    """
    æ¸…ç†DbgBlkIdå­—ç¬¦ä¸²ï¼Œå»æ‰å‰ç¼€çš„.å’Œåç¼€çš„()åŠå…¶å†…å®¹
    
    Args:
        dbg_blk_id_str: åŸå§‹çš„DbgBlkIdå­—ç¬¦ä¸²ï¼Œå¦‚ ".PCSIP_dbg_client_DbgBlkId(0),"
        
    Returns:
        str: æ¸…ç†åçš„DbgBlkIdï¼Œå¦‚ "PCSIP_dbg_client_DbgBlkId"
    """
    # å»æ‰å‰å¯¼çš„.
    cleaned = dbg_blk_id_str.lstrip('.')
    
    # å»æ‰()åŠå…¶å†…å®¹å’Œåé¢çš„é€—å·
    cleaned = re.sub(r'\([^)]*\)[,]*', '', cleaned)
    
    # å»æ‰å…¶ä»–å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
    cleaned = cleaned.strip().rstrip(',')
    
    return cleaned

def analyze_unmatched_data(json_data, unmatched_excel_entries):
    """
    åˆ†ææœªåŒ¹é…çš„Excelå’ŒJSONæ•°æ®
    
    Args:
        json_data: JSONæ•°æ®å­—å…¸
        unmatched_excel_entries: æœªåŒ¹é…çš„Excelæ¡ç›®åˆ—è¡¨
        
    Returns:
        dict: åˆ†æç»“æœ
    """
    print("\nğŸ” å¼€å§‹åˆ†ææœªåŒ¹é…çš„æ•°æ®...")
    
    # æå–JSONä¸­çš„æ‰€æœ‰æ¨¡å—
    json_modules = set()
    for json_key, json_entry in json_data.items():
        module = json_entry.get('module', '')
        if module:
            json_modules.add(module)
    
    # æå–æœªåŒ¹é…Excelæ¡ç›®ä¸­çš„æ¨¡å—ï¼ˆå»é‡ï¼‰
    unmatched_excel_modules = set()
    for entry in unmatched_excel_entries:
        module = entry.get('module', '')
        if module:
            unmatched_excel_modules.add(module)
    
    # åˆ†ææ¨¡å—åŒ¹é…æƒ…å†µ
    json_only_modules = json_modules - unmatched_excel_modules
    excel_only_modules = unmatched_excel_modules - json_modules
    common_modules = json_modules & unmatched_excel_modules
    
    analysis_result = {
        'unmatched_excel_modules': sorted(list(unmatched_excel_modules)),
        'json_modules': sorted(list(json_modules)),
        'excel_only_modules': sorted(list(excel_only_modules)),
        'json_only_modules': sorted(list(json_only_modules)),
        'common_modules': sorted(list(common_modules)),
        'unmatched_excel_entries_count': len(unmatched_excel_entries),
        'unmatched_excel_modules_count': len(unmatched_excel_modules)
    }
    
    # è¾“å‡ºåˆ†æç»“æœ
    print(f"ğŸ“Š æœªåŒ¹é…åˆ†æç»“æœ:")
    print(f"   ğŸ“ æœªåŒ¹é…çš„Excelæ¡ç›®æ•°: {len(unmatched_excel_entries)}")
    print(f"   ğŸ·ï¸  æœªåŒ¹é…çš„Excelæ¨¡å—æ•°ï¼ˆå»é‡ï¼‰: {len(unmatched_excel_modules)}")
    print(f"   ğŸ“¦ JSONä¸­çš„æ€»æ¨¡å—æ•°: {len(json_modules)}")
    
    if excel_only_modules:
        print(f"\nâŒ ä»…åœ¨Excelä¸­å­˜åœ¨çš„æ¨¡å— ({len(excel_only_modules)}ä¸ª):")
        for module in excel_only_modules:
            print(f"     â€¢ {module}")
    
    if common_modules:
        print(f"\nâš ï¸  Excelå’ŒJSONéƒ½æœ‰ä½†æœªåŒ¹é…çš„æ¨¡å— ({len(common_modules)}ä¸ª):")
        for module in common_modules:
            print(f"     â€¢ {module}")
    
    if json_only_modules:
        print(f"\nâœ… ä»…åœ¨JSONä¸­å­˜åœ¨çš„æ¨¡å— ({len(json_only_modules)}ä¸ª):")
        for module in list(json_only_modules)[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"     â€¢ {module}")
        if len(json_only_modules) > 10:
            print(f"     ... è¿˜æœ‰ {len(json_only_modules) - 10} ä¸ª")
    
    return analysis_result

def save_unmatched_analysis_report(analysis_result, output_dir):
    """
    ä¿å­˜æœªåŒ¹é…åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
    
    Args:
        analysis_result: åˆ†æç»“æœå­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    """
    report_file = Path(output_dir) / "unmatched_analysis_report.json"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_result, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ æœªåŒ¹é…åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    # åŒæ—¶ä¿å­˜ä¸ºæ–‡æœ¬æ ¼å¼ï¼Œä¾¿äºé˜…è¯»
    txt_report_file = Path(output_dir) / "unmatched_analysis_report.txt"
    with open(txt_report_file, 'w', encoding='utf-8') as f:
        f.write("æœªåŒ¹é…æ•°æ®åˆ†ææŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"ç»Ÿè®¡æ¦‚è§ˆ:\n")
        f.write(f"  â€¢ æœªåŒ¹é…çš„Excelæ¡ç›®æ•°: {analysis_result['unmatched_excel_entries_count']}\n")
        f.write(f"  â€¢ æœªåŒ¹é…çš„Excelæ¨¡å—æ•°ï¼ˆå»é‡ï¼‰: {analysis_result['unmatched_excel_modules_count']}\n")
        f.write(f"  â€¢ JSONä¸­çš„æ€»æ¨¡å—æ•°: {len(analysis_result['json_modules'])}\n\n")
        
        f.write("æœªåŒ¹é…çš„Excelæ¨¡å—åˆ—è¡¨ï¼ˆå»é‡ï¼‰:\n")
        f.write("-" * 30 + "\n")
        for module in analysis_result['unmatched_excel_modules']:
            f.write(f"  â€¢ {module}\n")
        
        if analysis_result['excel_only_modules']:
            f.write(f"\nä»…åœ¨Excelä¸­å­˜åœ¨çš„æ¨¡å— ({len(analysis_result['excel_only_modules'])}ä¸ª):\n")
            f.write("-" * 30 + "\n")
            for module in analysis_result['excel_only_modules']:
                f.write(f"  â€¢ {module}\n")
        
        if analysis_result['common_modules']:
            f.write(f"\nExcelå’ŒJSONéƒ½æœ‰ä½†æœªåŒ¹é…çš„æ¨¡å— ({len(analysis_result['common_modules'])}ä¸ª):\n")
            f.write("-" * 30 + "\n")
            for module in analysis_result['common_modules']:
                f.write(f"  â€¢ {module}\n")
    
    print(f"ğŸ“„ æ–‡æœ¬ç‰ˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {txt_report_file}")

def integrate_json_excel_data(json_file_path, excel_file_path, output_file_path):
    """
    æ•´åˆJSONå’ŒExcelæ•°æ®
    
    Args:
        json_file_path: JSONæ–‡ä»¶è·¯å¾„
        excel_file_path: Excelæ–‡ä»¶è·¯å¾„
        output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        tuple: (integrated_data, unmatched_analysis)
    """
    
    # è¯»å–JSONæ•°æ®
    print("ğŸ“– è¯»å–JSONæ–‡ä»¶...")
    if not os.path.isabs(json_file_path):
        json_file_path = os.path.join(os.path.dirname(__file__), '..', 'output', json_file_path)
    
    with open(json_file_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    
    print(f"âœ… JSONæ–‡ä»¶åŒ…å« {len(json_data)} ä¸ªæ¡ç›®")
    
    # è¯»å–Excelæ•°æ®
    print("ğŸ“Š è¯»å–Excel mappingæ•°æ®...")
    excel_mapping = read_excel_mapping_data(excel_file_path)
    
    if not excel_mapping:
        print("âŒ æ²¡æœ‰è¯»å–åˆ°æœ‰æ•ˆçš„Excelæ˜ å°„æ•°æ®")
        return None, None
    
    # åˆ›å»ºExcelæ•°æ®çš„æŸ¥æ‰¾å­—å…¸
    excel_lookup = {}
    for entry in excel_mapping:
        key = f"{entry['module']}::{entry['instance']}"
        if key not in excel_lookup:
            excel_lookup[key] = []
        excel_lookup[key].append(entry)
    
    print(f"âœ… åˆ›å»ºäº† {len(excel_lookup)} ä¸ªæ¨¡å—::å®ä¾‹æ˜ å°„")
    
    # è®°å½•åŒ¹é…æƒ…å†µ
    matched_excel_keys = set()
    unmatched_excel_entries = []
    
    # æ•´åˆæ•°æ®
    print("ğŸ”„ å¼€å§‹æ•°æ®æ•´åˆ...")
    updated_count = 0
    cleaned_count = 0
    
    for json_key, json_entry in json_data.items():
        module = json_entry.get('module', '')
        instance = json_entry.get('instance', '')
        lookup_key = f"{module}::{instance}"
        
        # å¤„ç†pairsæ•°ç»„
        if 'pairs' in json_entry:
            for pair in json_entry['pairs']:
                # æ¸…ç†DbgBlkId
                if 'DbgBlkId' in pair:
                    original_dbg = pair['DbgBlkId']
                    cleaned_dbg = clean_dbg_blk_id(original_dbg)
                    pair['DbgBlkId'] = cleaned_dbg
                    cleaned_count += 1
                
                # æŸ¥æ‰¾åŒ¹é…çš„Excelæ•°æ®
                if lookup_key in excel_lookup:
                    for excel_entry in excel_lookup[lookup_key]:
                        # åŒ¹é…DbgBlkId
                        if cleaned_dbg == excel_entry['dbg_blk_id']:
                            # æ›´æ–°tile_name
                            if excel_entry['tile_name'] and not pair.get('tile_name'):
                                pair['tile_name'] = excel_entry['tile_name']
                                updated_count += 1
                                # è®°å½•å·²åŒ¹é…çš„Excelæ¡ç›®
                                matched_excel_keys.add(lookup_key)
                                break
    
    # æ‰¾å‡ºæœªåŒ¹é…çš„Excelæ¡ç›®
    for entry in excel_mapping:
        lookup_key = f"{entry['module']}::{entry['instance']}"
        if lookup_key not in matched_excel_keys:
            unmatched_excel_entries.append(entry)
    
    print(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªDbgBlkId")
    print(f"âœ… æ›´æ–°äº† {updated_count} ä¸ªtile_name")
    print(f"ğŸ“Š Excelæ€»æ¡ç›®: {len(excel_mapping)}")
    print(f"ğŸ“Š å·²åŒ¹é…æ¡ç›®: {len(matched_excel_keys)}")
    print(f"ğŸ“Š æœªåŒ¹é…æ¡ç›®: {len(unmatched_excel_entries)}")
    
    # åˆ†ææœªåŒ¹é…çš„æ•°æ®
    unmatched_analysis = analyze_unmatched_data(json_data, unmatched_excel_entries)
    
    # ä¿å­˜æ•´åˆåçš„æ•°æ®
    print("ğŸ’¾ ä¿å­˜æ•´åˆåçš„æ•°æ®...")
    if not os.path.isabs(output_file_path):
        output_file_path = os.path.join(os.path.dirname(__file__), '..', 'output', output_file_path)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_file_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file_path, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•´åˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file_path}")
    
    return json_data, unmatched_analysis

def analyze_integration_results(original_json_path, integrated_json_path):
    """
    åˆ†ææ•´åˆç»“æœ
    """
    print("\nğŸ“Š åˆ†ææ•´åˆç»“æœ...")
    
    # è¯»å–åŸå§‹JSON
    with open(original_json_path, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    # è¯»å–æ•´åˆåçš„JSON
    with open(integrated_json_path, 'r', encoding='utf-8') as f:
        integrated_data = json.load(f)
    
    # ç»Ÿè®¡æ•°æ®
    original_empty_tiles = 0
    integrated_filled_tiles = 0
    total_pairs = 0
    
    for key, entry in original_data.items():
        if 'pairs' in entry:
            for pair in entry['pairs']:
                total_pairs += 1
                if not pair.get('tile_name'):
                    original_empty_tiles += 1
    
    for key, entry in integrated_data.items():
        if 'pairs' in entry:
            for pair in entry['pairs']:
                if pair.get('tile_name'):
                    integrated_filled_tiles += 1
    
    print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
    print(f"   æ€»é…å¯¹æ•°: {total_pairs}")
    print(f"   åŸå§‹ç©ºtile_name: {original_empty_tiles}")
    print(f"   æ•´åˆåå·²å¡«å……: {integrated_filled_tiles}")
    print(f"   å¡«å……æˆåŠŸç‡: {integrated_filled_tiles/total_pairs*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹JSONå’ŒExcelæ•°æ®æ•´åˆ...")
    print("=" * 60)
    
    try:
        # æ•´åˆæ•°æ®
        integrated_data, unmatched_analysis = integrate_json_excel_data(
            "chip_blocks.json",
            "Mapping.xlsx", 
            "chip_blocks_integrated.json"
        )
        
        if integrated_data and unmatched_analysis:
            # åˆ†æç»“æœ
            analyze_integration_results(
                os.path.join(os.path.dirname(__file__), '..', 'output', 'chip_blocks.json'),
                os.path.join(os.path.dirname(__file__), '..', 'output', 'chip_blocks_integrated.json')
            )
            
            print("\nğŸ‰ æ•°æ®æ•´åˆå®Œæˆï¼")
            print(f"ğŸ“Š æœªåŒ¹é…Excelæ¨¡å—æ•°: {unmatched_analysis['unmatched_excel_modules_count']}")
        else:
            print("âŒ æ•°æ®æ•´åˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ•´åˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()