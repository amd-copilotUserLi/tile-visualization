#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONå’ŒExcelæ•°æ®æ•´åˆå·¥å…·
ç”¨äºæ•´åˆchip_blocks.jsonå’ŒMapping.xlsxçš„æ•°æ®
"""

import pandas as pd
import json
import os
import re
from pathlib import Path

def read_excel_mapping_data(excel_file_path):
    """
    è¯»å–Excelæ–‡ä»¶çš„Aã€Bã€Cã€Fåˆ—æ•°æ®ï¼ˆè·³è¿‡è¡¨å¤´ï¼‰
    
    Args:
        excel_file_path: Excelæ–‡ä»¶è·¯å¾„
        
    Returns:
        list: åŒ…å«mappingæ•°æ®çš„å­—å…¸åˆ—è¡¨
    """
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    if not os.path.isabs(excel_file_path):
        excel_file_path = os.path.join(os.path.dirname(__file__), '..', 'input', excel_file_path)
    
    excel_file_path = os.path.abspath(excel_file_path)
    
    if not os.path.exists(excel_file_path):
        raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file_path}")
    
    try:
        # è¯»å–Excelæ–‡ä»¶çš„Aã€Bã€Cã€Fåˆ—ï¼ˆç´¢å¼•ä¸º0ã€1ã€2ã€5ï¼‰
        df = pd.read_excel(excel_file_path, usecols=[0, 1, 2, 5], skiprows=1, header=None)
        
        # é‡å‘½ååˆ—
        df.columns = ['module', 'instance', 'dbg_blk_id', 'tile_name']
        
        # è¿‡æ»¤æ‰æ‰€æœ‰åˆ—éƒ½ä¸ºç©ºçš„è¡Œ
        mapping_data = []
        for _, row in df.iterrows():
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®ï¼ˆè‡³å°‘moduleã€instanceã€dbg_blk_idä¸ä¸ºç©ºï¼‰
            if (pd.notna(row['module']) and str(row['module']).strip() and
                pd.notna(row['instance']) and str(row['instance']).strip() and
                pd.notna(row['dbg_blk_id']) and str(row['dbg_blk_id']).strip()):
                
                mapping_entry = {
                    'module': str(row['module']).strip(),
                    'instance': str(row['instance']).strip(),
                    'dbg_blk_id': str(row['dbg_blk_id']).strip(),
                    'tile_name': str(row['tile_name']).strip() if pd.notna(row['tile_name']) and str(row['tile_name']).strip() else ""
                }
                mapping_data.append(mapping_entry)
        
        print(f"âœ… ä»Excelæ–‡ä»¶è¯»å–åˆ° {len(mapping_data)} æ¡æœ‰æ•ˆçš„mappingæ•°æ®")
        return mapping_data
        
    except Exception as e:
        print(f"âŒ è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def clean_dbg_blk_id(dbg_blk_id_str):
    """
    æ¸…ç†DbgBlkIdå­—ç¬¦ä¸²ï¼Œå»æ‰å‰ç¼€çš„.å’Œåç¼€çš„()åŠå…¶å†…å®¹
    
    Args:
        dbg_blk_id_str: åŸå§‹çš„DbgBlkIdå­—ç¬¦ä¸²ï¼Œå¦‚ ".PCSIP_dbg_client_DbgBlkId(0),"
        
    Returns:
        str: æ¸…ç†åçš„DbgBlkIdï¼Œå¦‚ "PCSIP_dbg_client_DbgBlkId"
    """
    # å»æ‰å‰å¯¼çš„.
    cleaned = dbg_blk_id_str.lstrip('.')
    
    # å»æ‰()åŠå…¶å†…å®¹å’Œåé¢çš„é€—å·
    cleaned = re.sub(r'\([^)]*\)[,]*', '', cleaned)
    
    # å»æ‰å…¶ä»–å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
    cleaned = cleaned.strip().rstrip(',')
    
    return cleaned

def integrate_json_excel_data(json_file_path, excel_file_path, output_file_path):
    """
    æ•´åˆJSONå’ŒExcelæ•°æ®
    
    Args:
        json_file_path: JSONæ–‡ä»¶è·¯å¾„
        excel_file_path: Excelæ–‡ä»¶è·¯å¾„
        output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    
    # è¯»å–JSONæ•°æ®
    print("ğŸ“– è¯»å–JSONæ–‡ä»¶...")
    if not os.path.isabs(json_file_path):
        json_file_path = os.path.join(os.path.dirname(__file__), '..', 'output', json_file_path)
    
    with open(json_file_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    
    print(f"âœ… JSONæ–‡ä»¶åŒ…å« {len(json_data)} ä¸ªæ¡ç›®")
    
    # è¯»å–Excelæ•°æ®
    print("ğŸ“Š è¯»å–Excel mappingæ•°æ®...")
    excel_mapping = read_excel_mapping_data(excel_file_path)
    
    if not excel_mapping:
        print("âŒ æ²¡æœ‰è¯»å–åˆ°æœ‰æ•ˆçš„Excelæ˜ å°„æ•°æ®")
        return
    
    # åˆ›å»ºExcelæ•°æ®çš„æŸ¥æ‰¾å­—å…¸
    excel_lookup = {}
    for entry in excel_mapping:
        key = f"{entry['module']}::{entry['instance']}"
        if key not in excel_lookup:
            excel_lookup[key] = []
        excel_lookup[key].append(entry)
    
    print(f"âœ… åˆ›å»ºäº† {len(excel_lookup)} ä¸ªæ¨¡å—::å®ä¾‹æ˜ å°„")
    
    # æ•´åˆæ•°æ®
    print("ğŸ”„ å¼€å§‹æ•°æ®æ•´åˆ...")
    updated_count = 0
    cleaned_count = 0
    
    for json_key, json_entry in json_data.items():
        module = json_entry.get('module', '')
        instance = json_entry.get('instance', '')
        lookup_key = f"{module}::{instance}"
        
        # å¤„ç†pairsæ•°ç»„
        if 'pairs' in json_entry:
            for pair in json_entry['pairs']:
                # æ¸…ç†DbgBlkId
                if 'DbgBlkId' in pair:
                    original_dbg = pair['DbgBlkId']
                    cleaned_dbg = clean_dbg_blk_id(original_dbg)
                    pair['DbgBlkId'] = cleaned_dbg
                    cleaned_count += 1
                
                # æŸ¥æ‰¾åŒ¹é…çš„Excelæ•°æ®
                if lookup_key in excel_lookup:
                    for excel_entry in excel_lookup[lookup_key]:
                        # åŒ¹é…DbgBlkId
                        if cleaned_dbg == excel_entry['dbg_blk_id']:
                            # æ›´æ–°tile_name
                            if excel_entry['tile_name'] and not pair.get('tile_name'):
                                pair['tile_name'] = excel_entry['tile_name']
                                updated_count += 1
                                break
    
    print(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªDbgBlkId")
    print(f"âœ… æ›´æ–°äº† {updated_count} ä¸ªtile_name")
    
    # ä¿å­˜æ•´åˆåçš„æ•°æ®
    print("ğŸ’¾ ä¿å­˜æ•´åˆåçš„æ•°æ®...")
    if not os.path.isabs(output_file_path):
        output_file_path = os.path.join(os.path.dirname(__file__), '..', 'output', output_file_path)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_file_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file_path, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ•´åˆå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file_path}")
    
    return json_data

def analyze_integration_results(original_json_path, integrated_json_path):
    """
    åˆ†ææ•´åˆç»“æœ
    """
    print("\nğŸ“Š åˆ†ææ•´åˆç»“æœ...")
    
    # è¯»å–åŸå§‹JSON
    with open(original_json_path, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    # è¯»å–æ•´åˆåçš„JSON
    with open(integrated_json_path, 'r', encoding='utf-8') as f:
        integrated_data = json.load(f)
    
    # ç»Ÿè®¡æ•°æ®
    original_empty_tiles = 0
    integrated_filled_tiles = 0
    total_pairs = 0
    
    for key, entry in original_data.items():
        if 'pairs' in entry:
            for pair in entry['pairs']:
                total_pairs += 1
                if not pair.get('tile_name'):
                    original_empty_tiles += 1
    
    for key, entry in integrated_data.items():
        if 'pairs' in entry:
            for pair in entry['pairs']:
                if pair.get('tile_name'):
                    integrated_filled_tiles += 1
    
    print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
    print(f"   æ€»é…å¯¹æ•°: {total_pairs}")
    print(f"   åŸå§‹ç©ºtile_name: {original_empty_tiles}")
    print(f"   æ•´åˆåå·²å¡«å……: {integrated_filled_tiles}")
    print(f"   å¡«å……æˆåŠŸç‡: {integrated_filled_tiles/total_pairs*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹JSONå’ŒExcelæ•°æ®æ•´åˆ...")
    print("=" * 60)
    
    try:
        # æ•´åˆæ•°æ®
        integrated_data = integrate_json_excel_data(
            "chip_blocks.json",
            "Mapping.xlsx", 
            "chip_blocks_integrated.json"
        )
        
        if integrated_data:
            # åˆ†æç»“æœ
            analyze_integration_results(
                os.path.join(os.path.dirname(__file__), '..', 'output', 'chip_blocks.json'),
                os.path.join(os.path.dirname(__file__), '..', 'output', 'chip_blocks_integrated.json')
            )
            
            print("\nğŸ‰ æ•°æ®æ•´åˆå®Œæˆï¼")
        else:
            print("âŒ æ•°æ®æ•´åˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ•´åˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main()